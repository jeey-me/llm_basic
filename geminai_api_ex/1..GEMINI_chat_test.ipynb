{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "541f751b-6a61-4c78-ace2-5f758a362664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # .env 파일 로드\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "# print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce6d44dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예시 이미지가 'saved_original_poodle.png' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image # Make sure you have 'Pillow' installed (pip install Pillow)\n",
    "from io import BytesIO\n",
    "\n",
    "# Assume 'image' is your file path string as before\n",
    "image_path = r'C:\\Users\\Admin\\kpmg_future_lab\\llm_basic\\geminai_api_ex\\output.png'\n",
    "\n",
    "try:\n",
    "    # 1. Load the image from the path into a PIL Image object\n",
    "    #    This 'image' variable will now be an actual image object\n",
    "    #    If you're getting the image from a GenAI response,\n",
    "    #    the 'image = Image.open(BytesIO(part.inline_data.data))' line\n",
    "    #    from your previous code would fulfill this step.\n",
    "    image_object = Image.open(image_path)\n",
    "\n",
    "    # Now, 'image_object' is a PIL Image, which has the .copy() method\n",
    "    if image_object is not None:\n",
    "        temp_processed_image = image_object.copy() # 원본을 복사해서 사용\n",
    "\n",
    "        # 이미지 보여주기 (선택 사항)\n",
    "        # temp_processed_image.show()\n",
    "\n",
    "        # 이미지 저장하기\n",
    "        save_path_simulation = \"saved_original_poodle.png\"\n",
    "        temp_processed_image.save(save_path_simulation)\n",
    "        print(f\"예시 이미지가 '{save_path_simulation}' 파일로 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"이미지를 로드할 수 없어 저장 예시를 실행할 수 없습니다.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{image_path}' 경로에서 이미지를 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"이미지 처리 또는 저장 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "876880e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 이미지를 base64로 변환하는 함수\n",
    "def image_to_base64(image):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format='JPEG')\n",
    "    img_data = buffer.getvalue()\n",
    "    return base64.b64encode(img_data).decode()\n",
    "\n",
    "# 클라이언트 설정\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# 이미지 로드 및 변환\n",
    "image = PIL.Image.open('./lady.jpg')\n",
    "image_b64 = image_to_base64(image)\n",
    "\n",
    "text_input = ('Hi, This is a picture of me. '\n",
    "              'Can you add a llama next to me?')\n",
    "\n",
    "# API 호출\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "    contents=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"parts\": [\n",
    "                {\"text\": text_input},\n",
    "                {\"inline_data\": {\n",
    "                    \"mime_type\": \"image/jpeg\",\n",
    "                    \"data\": image_b64\n",
    "                }}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_modalities=['TEXT', 'IMAGE']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "847af78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: I will add a fluffy, white llama standing calmly next to you in the grassy field, ensuring it is in proportion to your size and fits naturally into the existing outdoor scene with the distant hill and lighthouse.\n",
      "\n",
      "Image saved: ./generated_images/generated_image_20250528_152419_1.jpg\n",
      "All outputs saved in: ./generated_images\n"
     ]
    }
   ],
   "source": [
    "# 결과 처리 및 저장\n",
    "output_dir = './generated_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "for i, part in enumerate(response.candidates[0].content.parts):\n",
    "    if part.text is not None:\n",
    "        print(f\"Generated text: {part.text}\")\n",
    "        \n",
    "        # 텍스트도 저장하고 싶다면\n",
    "        with open(f'{output_dir}/response_text_{timestamp}.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(part.text)\n",
    "            \n",
    "    elif part.inline_data is not None:\n",
    "        # 이미지 데이터를 PIL Image로 변환\n",
    "        image_data = part.inline_data.data\n",
    "        \n",
    "        # base64 문자열인 경우 디코딩\n",
    "        if isinstance(image_data, str):\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "        else:\n",
    "            image_bytes = image_data\n",
    "            \n",
    "        # PIL Image로 변환\n",
    "        generated_image = Image.open(BytesIO(image_bytes))\n",
    "        \n",
    "        # 이미지 저장\n",
    "        output_filename = f'{output_dir}/generated_image_{timestamp}_{i}.jpg'\n",
    "        generated_image.save(output_filename, 'JPEG', quality=95)\n",
    "        \n",
    "        print(f\"Image saved: {output_filename}\")\n",
    "        \n",
    "        # 이미지 표시 (선택사항)\n",
    "        generated_image.show()\n",
    "\n",
    "print(f\"All outputs saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab311413",
   "metadata": {},
   "source": [
    "# 유튜브"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72c64373",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='models/gemini-2.0-flash',\n",
    "    contents=types.Content(\n",
    "        parts=[\n",
    "            types.Part(\n",
    "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=9hE5-98ZeCg')\n",
    "            ),\n",
    "            types.Part(text='Please summarize the video in 3 sentences.')\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9187eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! This video is a demonstration of Gemini 2.0's ability to interact with Google's AI Studio. In the video, a live stream is cast to the AI studio, and the narrator asks the AI to read a document that is being streamed. The narrator then asks the AI to summarize the demonstration and read the video's ending card.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec4e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
